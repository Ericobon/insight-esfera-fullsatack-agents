# Vertex AI RAG Agent with ADK

ğŸ§  InsightEsfera - Equipe de Agentes de IA
RepositÃ³rio: https://github.com/Ericobon/insight-esfera-fullsatack-agents

1. VisÃ£o Geral do Projeto
Este repositÃ³rio materializa a visÃ£o da InsightEsfera de transformar desafios de negÃ³cios em oportunidades de crescimento atravÃ©s de soluÃ§Ãµes data-driven e automaÃ§Ã£o inteligente. Desenvolvemos e implementamos um time colaborativo de agentes de InteligÃªncia Artificial no Google Cloud Platform (GCP), focado em otimizar a entrega de valor aos nossos clientes.

Nosso time de agentes Ã© projetado para atuar como uma equipe de consultoria de dados e IA altamente eficiente, onde cada agente possui um papel bem definido, comunica-se de forma inteligente e contribui para a resoluÃ§Ã£o de tarefas complexas, sob a orquestraÃ§Ã£o de um Agente LÃ­der TÃ©cnico.

Objetivos Chave:

AutomaÃ§Ã£o Inteligente: Automatizar e otimizar a coleta, engenharia, anÃ¡lise, modelagem e integraÃ§Ã£o de dados.
DecisÃµes Data-Driven: Fornecer insights acionÃ¡veis e baseados em evidÃªncias.
Escalabilidade e Custo-BenefÃ­cio: Utilizar a infraestrutura serverless do GCP para garantir flexibilidade e otimizaÃ§Ã£o de recursos (incluindo o consumo de tokens de LLM).
ColaboraÃ§Ã£o Eficaz: Estabelecer protocolos de comunicaÃ§Ã£o e compartilhamento de conhecimento entre agentes.
2. Componentes e ServiÃ§os do Google Cloud Platform (GCP)
2.1. Ambiente de Desenvolvimento e OrquestraÃ§Ã£o
ServiÃ§o: Vertex AI Workbench (Managed Notebooks)
Nome da InstÃ¢ncia: ie-agents
ProprietÃ¡rio (Conta de ServiÃ§o Principal): 487071349303-compute@developer.gserviceaccount.com
RegiÃ£o: us-central1 (Iowa) - Garante proximidade e latÃªncia otimizada para os serviÃ§os do Vertex AI.
Tipo de MÃ¡quina: e2-standard-4 (4 vCPUs, 16 GB RAM) - Balanceado para desenvolvimento e orquestraÃ§Ã£o sem GPU (o LLM Ã© externo).
Uso: Ambiente principal para desenvolvimento, depuraÃ§Ã£o e execuÃ§Ã£o inicial do Agente Tech Lead e das funÃ§Ãµes-ferramentas.
2.2. Modelos de Linguagem (LLMs)
Utilizamos modelos de ponta do Vertex AI para o raciocÃ­nio e geraÃ§Ã£o de conteÃºdo dos nossos agentes.

Para RaciocÃ­nio Complexo e OrquestraÃ§Ã£o (Agente Tech Lead):
Modelo: Claude 3 Opus (da Anthropic via Vertex AI Model Garden) - Excelente para compreensÃ£o complexa, raciocÃ­nio de mÃºltiplos passos e planejamento.
Uso: SerÃ¡ o "cÃ©rebro" principal do Agente Tech Lead para decompor tarefas, delegar e sintetizar.
Para GeraÃ§Ã£o Aumentada por RecuperaÃ§Ã£o (Agente RAG):
Modelo: Gemini 2.5 Flash Preview 04-17 (do Google via Vertex AI) - Otimizado para alta performance e menor latÃªncia em operaÃ§Ãµes RAG.
Uso: Pelo RagAgent para buscas e respostas baseadas em corpora de documentos.
Para GeraÃ§Ã£o de Embeddings (Interno ao RAG Engine):
Modelo: publishers/google/models/text-embedding-005 (ou similar, gerenciado pelo Vertex AI RAG Engine).
Uso: Automaticamente pelo Vertex AI RAG Engine para criar as representaÃ§Ãµes vetoriais dos documentos e consultas para a busca de similaridade.
2.3. Armazenamento de Dados e MemÃ³ria Persistente
ServiÃ§o: Cloud Storage
Nome do Bucket: insightesfera-companies
Estrutura de Pastas:
insightesfera-companies/
â”œâ”€â”€ companies/
â”‚   â”œâ”€â”€ [NOME_CLIENTE_1]/  # Ex: "InsightEsfera" (para projetos internos), "ClienteXYZ"
â”‚   â”‚   â”œâ”€â”€ projects/
â”‚   â”‚   â”‚   â”œâ”€â”€ [NOME_PROJETO_CLIENTE_1_A]/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ data/             # Dados brutos/processados especÃ­ficos do projeto
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ reports/          # RelatÃ³rios gerados pelo agente
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ memory/             # MemÃ³ria de longo prazo especÃ­fica do cliente
â”‚   â”‚       â”œâ”€â”€ client_context.json   # Dados de preferÃªncia, histÃ³rico, contatos
â”‚   â”‚       â””â”€â”€ project_summary_latest.json # Resumo dos projetos do cliente
â”‚   â””â”€â”€ ...
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ memory/                 # MemÃ³ria de longo prazo dos prÃ³prios agentes
â”‚   â”‚   â”œâ”€â”€ tech_lead_knowledge.json  # Conhecimento do Tech Lead sobre fluxos e padrÃµes
â”‚   â”‚   â”œâ”€â”€ data_engineer_skills.json # Conhecimento do Eng. Dados sobre fontes e formatos
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ scripts/                # Templates de scripts ou snippets de cÃ³digo para agentes
â”‚       â”œâ”€â”€ data_collection_templates.py
â”‚       â””â”€â”€ ml_model_templates.py
â”œâ”€â”€ internal/                   # Dados internos da consultoria (templates de proposta, documentaÃ§Ã£o interna)
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ ...
â””â”€â”€ temp_github_ingest/         # **NOVO:** Pasta temporÃ¡ria para conteÃºdo clonado do GitHub antes da ingestÃ£o RAG.
Uso: RepositÃ³rio centralizado para dados brutos, resultados, memÃ³ria de longo prazo (LTM) de clientes/agentes e arquivos temporÃ¡rios.
2.4. Bases de Conhecimento RAG
ServiÃ§o: Vertex AI RAG Engine (anteriormente parte do Vertex AI Search)
Uso: Armazena os corpora (coleÃ§Ãµes de documentos) que sÃ£o a base de conhecimento para a funcionalidade RAG. Os documentos sÃ£o processados (chunking, embedding, indexaÃ§Ã£o) automaticamente por este serviÃ§o.
LocalizaÃ§Ã£o no Console: Vertex AI > RAG Engine.
2.5. ComunicaÃ§Ã£o Externa e Serverless (Futura Escalabilidade)
ServiÃ§o (Futuro): Cloud Run ou Cloud Functions
Uso: Para hospedar o Agente Tech Lead em produÃ§Ã£o, permitindo que ele seja acionado por requisiÃ§Ãµes HTTP (ex: de plataformas como Twilio para integraÃ§Ã£o WhatsApp) e escale para zero instÃ¢ncias quando inativo, otimizando custos.
ServiÃ§o (IntegraÃ§Ã£o WhatsApp - Futuro): Twilio ou Dialogflow CX
Uso: Gateway para comunicaÃ§Ã£o via WhatsApp com o Agente Tech Lead.
3. Arquitetura e Fluxo de Trabalho do Time de Agentes
Nosso time de agentes segue uma arquitetura colaborativa e hierÃ¡rquica, orquestrada pelo Agente Tech Lead.

3.1. Agente Tech Lead (Orquestrador Principal)
Papel: O Agente LÃ­der TÃ©cnico Ã© o maestro da equipe. Ele recebe as requisiÃ§Ãµes, planeja a execuÃ§Ã£o, delega tarefas aos agentes especializados e sintetiza os resultados. Possui uma visÃ£o holÃ­stica e orientada a negÃ³cios.
LLM: Claude 3 Opus (via Vertex AI).
Fluxo de InteraÃ§Ã£o:
Recebe uma requisiÃ§Ã£o (ex: "Analise os dados de vendas do cliente X e identifique as principais tendÃªncias do Ãºltimo trimestre, incorporando tambÃ©m a documentaÃ§Ã£o do novo produto Y que estÃ¡ no nosso GitHub privado").
Planejamento: DecompÃµe a requisiÃ§Ã£o em subtarefas (ex: "Verificar/Criar corpus do Cliente X", "Adicionar documentaÃ§Ã£o do produto Y ao corpus", "Coletar dados de vendas", "Analisar dados", "Sintetizar relatÃ³rio").
DelegaÃ§Ã£o: Chama as ferramentas dos agentes especializados apropriados para cada subtarefa.
CoordenaÃ§Ã£o: Monitora o status das subtarefas, lida com erros e combina os resultados parciais.
SÃ­ntese: Utiliza o Claude Opus para gerar o relatÃ³rio final ou a resposta completa, adicionando contexto e insights estratÃ©gicos.
PersistÃªncia: Salva o histÃ³rico da interaÃ§Ã£o e os resultados importantes na memÃ³ria de longo prazo (Cloud Storage).
3.2. Agentes Especializados (Sub-Agentes)
Cada agente especializado Ã© uma funÃ§Ã£o-ferramenta ou um mÃ³dulo de cÃ³digo Python invocado pelo Agente Tech Lead, utilizando um LLM e ferramentas especÃ­ficas para sua Ã¡rea.

Vertex AI RAG Agent (rag_agent - Este repositÃ³rio):
Papel: Especialista em gerenciamento e consulta de bases de conhecimento documentais no Vertex AI RAG Engine.
LLM: Gemini 2.5 Flash (via Vertex AI) - Otimizado para RAG.
Ferramentas Expostas: rag_query, list_corpora, create_corpus, add_data (com suporte a GitHub), get_corpus_info, delete_corpus, delete_document.
ComunicaÃ§Ã£o: Recebe instruÃ§Ãµes do Agente Tech Lead (via chamadas Python para suas funÃ§Ãµes-ferramentas) e retorna resultados estruturados.
Agente Engenheiro de Dados:
Papel: ResponsÃ¡vel pela coleta, limpeza, transformaÃ§Ã£o e validaÃ§Ã£o de dados de diversas fontes (BigQuery, Cloud Storage, APIs externas, bancos de dados).
LLM: Gemini 1.5 Pro ou Claude 3 Sonnet (via Vertex AI) - Bom para lÃ³gica de transformaÃ§Ã£o e validaÃ§Ã£o de dados.
Ferramentas Expostas: fetch_from_bigquery(query), transform_data(data, schema), validate_data(data, rules), load_to_gcs(data, path).
ComunicaÃ§Ã£o: Recebe requisiÃ§Ãµes de coleta/transformaÃ§Ã£o do Tech Lead e entrega dados limpos/transformados (salvos em GCS) ou confirmaÃ§Ãµes.
Agente Cientista de Dados:
Papel: Focado em anÃ¡lise de dados, identificaÃ§Ã£o de padrÃµes, construÃ§Ã£o/avaliaÃ§Ã£o de modelos preditivos e geraÃ§Ã£o de insights acionÃ¡veis.
LLM: Claude 3 Opus ou Gemini 1.5 Pro (via Vertex AI) - Para raciocÃ­nio analÃ­tico avanÃ§ado.
Ferramentas Expostas: analyze_trends(data), run_ml_model(model_id, features), generate_insights(analysis_results), create_dashboard_spec(insights).
ComunicaÃ§Ã£o: Recebe dados do Tech Lead (geralmente via GCS), realiza anÃ¡lises e retorna insights ou especificaÃ§Ãµes de modelos.
Agente Desenvolvedor Full-stack:
Papel: Gera, refatora e integra cÃ³digo para APIs, scripts de automaÃ§Ã£o e interfaces simples, garantindo a interoperabilidade dos componentes.
LLM: Gemini 1.5 Pro (via Vertex AI) - Para geraÃ§Ã£o de cÃ³digo e entendimento de estruturas de software.
Ferramentas Expostas: generate_api_code(spec), create_automation_script(task_description), integrate_api(api1_spec, api2_spec).
ComunicaÃ§Ã£o: Recebe especificaÃ§Ãµes do Tech Lead e retorna snippets de cÃ³digo ou confirmaÃ§Ãµes de integraÃ§Ã£o.
3.3. Papel Colaborativo Detalhado
A colaboraÃ§Ã£o ocorre atravÃ©s de um loop contÃ­nuo de delegaÃ§Ã£o e feedback, mediado pelo Agente Tech Lead:

DelegaÃ§Ã£o Inteligente: O Tech Lead, usando seu LLM (Claude Opus), analisa a requisiÃ§Ã£o e "decide" qual agente especializado e qual de suas ferramentas sÃ£o mais adequados para a prÃ³xima subtarefa.
Chamada de Ferramenta (Tool Calling): O Tech Lead invoca a funÃ§Ã£o Python que representa a ferramenta do agente especializado (ex: rag_agent_instance.add_data()).
ExecuÃ§Ã£o da Subtarefa: O agente especializado (o cÃ³digo Python por trÃ¡s da ferramenta) executa sua lÃ³gica, que pode envolver chamadas a serviÃ§os do GCP (Vertex AI Search, BigQuery, Cloud Storage) ou a outros LLMs especÃ­ficos (como o Gemini Flash para RAG).
Compartilhamento de Resultados: Os resultados das subtarefas sÃ£o retornados ao Tech Lead (via retorno da funÃ§Ã£o Python). Para grandes volumes de dados, os resultados sÃ£o salvos em Cloud Storage, e apenas a referÃªncia (URL do GCS) Ã© passada.
Ciclo de Feedback: O Tech Lead avalia o resultado. Se for insuficiente, ambÃ­guo ou necessitar de correÃ§Ã£o, ele pode solicitar refinamentos ou chamar outro agente para uma etapa diferente.
MemÃ³ria Compartilhada: A memÃ³ria de longo prazo no Cloud Storage (insightesfera-companies/) serve como um "cÃ©rebro" compartilhado, onde os agentes podem persistir e recuperar informaÃ§Ãµes relevantes para o projeto atual ou histÃ³rico de clientes.
4. Detalhes de ImplementaÃ§Ã£o e Ferramentas
4.1. PermissÃµes de IAM (Identity and Access Management)
A Conta de ServiÃ§o principal da sua instÃ¢ncia do Vertex AI Workbench (487071349303-compute@developer.gserviceaccount.com no projeto silent-text-458716-c9) necessita das seguintes permissÃµes para operar todos os agentes e suas ferramentas:

roles/aiplatform.user: Essencial para interagir com a API Vertex AI (incluindo LLMs como Claude Opus, Gemini, e o Vertex AI Search/RAG Engine).
roles/storage.admin: Para gerenciar (ler, gravar, deletar) todos os objetos no bucket insightesfera-companies. (Para maior granularidade em produÃ§Ã£o, considere roles/storage.objectAdmin e roles/storage.objectViewer para pastas especÃ­ficas).
roles/bigquery.dataEditor: Se os agentes precisarem escrever dados no BigQuery.
roles/bigquery.dataViewer: Se os agentes precisarem ler dados do BigQuery.
roles/bigquery.jobUser: Para executar jobs de BigQuery.
roles/iam.serviceAccountUser: NecessÃ¡rio se o Agente Tech Lead for operar como outras contas de serviÃ§o mais granulares para sub-agentes (nÃ£o estritamente necessÃ¡rio para MVP).
roles/logging.logWriter: Para garantir que os logs da aplicaÃ§Ã£o sejam enviados para o Cloud Logging.
roles/sourcerepo.reader: Para ler repositÃ³rios no Cloud Source Repositories (se vocÃª optar por espelhar o GitHub para lÃ¡).
4.2. FunÃ§Ãµes-Ferramentas (Python)
As "mÃ£os" e "olhos" dos agentes. Implementadas em Python, sÃ£o invocadas pelo LLM do agente supervisor (ou o prÃ³prio agente, se for autÃ´nomo).

rag_agent/tools/add_data.py: Implementado! Inclui lÃ³gica para clonar repositÃ³rios GitHub para GCS e ingerir via Vertex AI RAG Engine.
rag_agent/tools/rag_query.py: Interage com o Vertex AI RAG Engine para consultas.
rag_agent/tools/create_corpus.py, list_corpora.py, get_corpus_info.py, delete_corpus.py, delete_document.py: Gerenciam os corpora no Vertex AI RAG Engine.
Novas Ferramentas para outros Agentes (futuro):
Engenheiro de Dados: fetch_from_bigquery, clean_and_transform_data, upload_to_gcs.
Cientista de Dados: run_descriptive_analysis, execute_prediction_model, generate_data_insights.
Dev Full-stack: generate_api_spec, create_boilerplate_code, perform_api_call.
4.3. EstratÃ©gias de MemÃ³ria e RAG (Boas PrÃ¡ticas e OtimizaÃ§Ã£o de Custos)
A implementaÃ§Ã£o de memÃ³ria eficiente e RAG Ã© crucial para a inteligÃªncia e custo-benefÃ­cio dos agentes.

MemÃ³ria de Curto Prazo (STM) - Gerenciamento de Janela de Contexto:
TÃ©cnica: MantÃ©m as Ãºltimas N interaÃ§Ãµes (mensagens/respostas) na memÃ³ria RAM do Agente Tech Lead.
OtimizaÃ§Ã£o de Custos: Usamos LLMs com grandes janelas de contexto (Claude Opus), mas Ã© vital monitorar o tamanho do prompt. Para conversas muito longas, implemente:
ResumizaÃ§Ã£o: O prÃ³prio LLM pode ser instruÃ­do a periodicamente resumir partes mais antigas da conversa, compactando o contexto e reduzindo o consumo de tokens.
Sliding Window: Manter apenas as X mensagens mais recentes.
MemÃ³ria de Longo Prazo (LTM) - RAG com Vertex AI RAG Engine:
TÃ©cnica: Documentos de conhecimento (clientes, projetos, internos) sÃ£o armazenados no Cloud Storage e indexados no Vertex AI RAG Engine.
Processo:
IngestÃ£o Otimizada: Documentos (incluindo de GitHub) sÃ£o divididos em chunks (pedacinhos de texto) e convertidos em embeddings pelo Vertex AI RAG Engine.
Busca de RelevÃ¢ncia (RAG): Quando uma pergunta surge, ela Ã© convertida em um embedding, e o Vertex AI RAG Engine encontra os chunks mais semanticamente relevantes na LTM.
Aumento do Prompt: Apenas os chunks mais relevantes sÃ£o adicionados ao prompt enviado ao LLM.
OtimizaÃ§Ã£o de Custos de Tokens: O RAG Ã© a tÃ©cnica principal para reduzir o volume de tokens enviado ao LLM, pois evita que o LLM precise "ler" toda a base de conhecimento a cada requisiÃ§Ã£o. VocÃª paga apenas pelos tokens do prompt mais os tokens dos chunks relevantes recuperados.
Escolha do Embedding Model: O Vertex AI RAG Engine gerencia o modelo de embedding (text-embedding-005 ou similar), que Ã© otimizado para custo e precisÃ£o.
4.4. Monitoramento, Rastreabilidade e Controle de Custos
Para cada componente e cada interaÃ§Ã£o:

Cloud Logging: Logs detalhados de todas as aÃ§Ãµes dos agentes (inÃ­cio/fim de tarefa, chamadas de ferramentas, erros, interaÃ§Ãµes com LLMs) para depuraÃ§Ã£o e rastreabilidade do fluxo de trabalho.
Cloud Monitoring:
MÃ©tricas de Plataforma: CPU, RAM (Workbench/Cloud Run), requisiÃ§Ãµes, latÃªncia (Cloud Run, Vertex AI Search).
MÃ©tricas Customizadas: NÃºmero de tarefas concluÃ­das/falhas por agente, latÃªncia mÃ©dia por tipo de tarefa, contagem de tokens (entrada/saÃ­da) por chamada de LLM (crucial para custo), volume de dados adicionados ao RAG Engine.
Alertas: NotificaÃ§Ãµes proativas sobre erros, alto consumo de recursos ou estouro de orÃ§amentos.
Cloud Trace: VisualizaÃ§Ã£o do caminho completo de uma requisiÃ§Ã£o (trace) atravÃ©s de mÃºltiplos agentes e serviÃ§os, essencial para identificar gargalos de latÃªncia. Instrumentar o cÃ³digo com OpenTelemetry SDK.
Cloud Billing: Monitoramento regular dos relatÃ³rios de custo, filtrando por Vertex AI (LLMs, RAG Engine), Cloud Storage e Compute Engine (Workbench). Configurar orÃ§amentos com alertas para controlar gastos.
5. Estrutura de CÃ³digo e Versionamento (GitHub)
Todo o cÃ³digo-fonte, prompts e scripts auxiliares sÃ£o versionados no GitHub, garantindo colaboraÃ§Ã£o e rastreabilidade.

RepositÃ³rio: https://github.com/Ericobon/insight-esfera-fullsatack-agents

Estrutura de Pastas:

insight-esfera-fullsatack-agents/
â”œâ”€â”€ docs/                             # DocumentaÃ§Ã£o do projeto (arquitetura, guias de setup)
â”œâ”€â”€ agents/                           # CÃ³digo dos agentes
â”‚   â”œâ”€â”€ rag_agent/                    # ImplementaÃ§Ã£o do Vertex AI RAG Agent
â”‚   â”‚   â”œâ”€â”€ agent.py                  # DefiniÃ§Ã£o do RagAgent (com o Instruction/Prompt)
â”‚   â”‚   â”œâ”€â”€ prompts/                  # Arquivos de prompts/persona especÃ­ficos do RagAgent
â”‚   â”‚   â”‚   â””â”€â”€ rag_agent_persona.txt
â”‚   â”‚   â”œâ”€â”€ tools/                    # ImplementaÃ§Ã£o das ferramentas do RagAgent
â”‚   â”‚   â”‚   â”œâ”€â”€ add_data.py           # **ATUALIZADO (com lÃ³gica GitHub)**
â”‚   â”‚   â”‚   â”œâ”€â”€ create_corpus.py
â”‚   â”‚   â”‚   â”œâ”€â”€ delete_corpus.py
â”‚   â”‚   â”‚   â”œâ”€â”€ delete_document.py
â”‚   â”‚   â”‚   â”œâ”€â”€ get_corpus_info.py
â”‚   â”‚   â”‚   â”œâ”€â”€ list_corpora.py
â”‚   â”‚   â”‚   â””â”€â”€ rag_query.py
â”‚   â”‚   â””â”€â”€ config.py                 # ConfiguraÃ§Ãµes do RagAgent (chunk size, etc.)
â”‚   â”œâ”€â”€ tech_lead_agent/              # **NOVO:** ImplementaÃ§Ã£o do Agente Tech Lead
â”‚   â”‚   â”œâ”€â”€ agent.py                  # DefiniÃ§Ã£o do TechLeadAgent (com o Instruction/Prompt)
â”‚   â”‚   â”œâ”€â”€ prompts/                  # Arquivos de prompts/persona especÃ­ficos do TechLeadAgent
â”‚   â”‚   â”‚   â””â”€â”€ tech_lead_persona.txt
â”‚   â”‚   â””â”€â”€ tools/                    # Ferramentas que o TechLeadAgent usa (incluindo chamar o RagAgent)
â”‚   â”‚       â”œâ”€â”€ query_knowledge_base.py # Exemplo: Ferramenta que chama o RagAgent
â”‚   â”‚       â””â”€â”€ ... (outras ferramentas para BigQuery, etc.)
â”‚   â”œâ”€â”€ data_engineer_agent/          # **PRÃ“XIMO PASSO:** Futuro Agente Engenheiro de Dados
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ data_scientist_agent/         # **PRÃ“XIMO PASSO:** Futuro Agente Cientista de Dados
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ dev_fullstack_agent/          # **PRÃ“XIMO PASSO:** Futuro Agente Dev Full-stack
â”‚       â””â”€â”€ ...
â”œâ”€â”€ notebooks/                        # Notebooks Jupyter para desenvolvimento e experimentaÃ§Ã£o
â”‚   â””â”€â”€ 01_adk_rag_agent_test.ipynb
â”œâ”€â”€ config/                           # Arquivos de configuraÃ§Ã£o globais (se houver)
â”œâ”€â”€ scripts/                          # Scripts de deploy, utilitÃ¡rios
â”œâ”€â”€ .env                              # **CRÃTICO:** VariÃ¡veis de ambiente LOCALMENTE (ADICIONADO AO .gitignore)
â”œâ”€â”€ .gitignore                        # Para ignorar arquivos sensÃ­veis e temporÃ¡rios
â”œâ”€â”€ README.md                         # Este arquivo
â””â”€â”€ requirements.txt                  # DependÃªncias Python (atualizado com `GitPython`)
Versionamento por Agentes de IA:
A contribuiÃ§Ã£o dos agentes de IA ao versionamento serÃ¡ de natureza colaborativa:

GeraÃ§Ã£o de Artefatos: Agentes (como o Dev Full-stack) podem gerar trechos de cÃ³digo ou especificaÃ§Ãµes que, apÃ³s revisÃ£o humana, podem ser comitados.
OtimizaÃ§Ã£o de Prompts: Insights de agentes sobre a eficÃ¡cia dos prompts podem levar a melhorias nos arquivos agents/prompts/, que sÃ£o entÃ£o versionados.
RelatÃ³rios e AnÃ¡lises: RelatÃ³rios ou sumarizaÃ§Ãµes gerados pelos agentes podem ser salvos no Cloud Storage e seus metadados versionados, com links nos relatÃ³rios gerados.
6. PrÃ³ximos Passos Cruciais para a IntegraÃ§Ã£o Completa
Agora que o RagAgent estÃ¡ funcionando e integrado ao GitHub, o foco Ã© construir o restante do time.

6.1. ConfiguraÃ§Ã£o do TechLeadAgent e OrquestraÃ§Ã£o
DefiniÃ§Ã£o do TechLeadAgent: Crie o arquivo agents/tech_lead_agent/agent.py definindo o Agent (com o Claude 3 Opus) e seu instruction (prompt).
CriaÃ§Ã£o das Ferramentas do Tech Lead:
Crie agents/tech_lead_agent/tools/query_knowledge_base.py (e outras ferramentas, se necessÃ¡rio). Esta ferramenta chamarÃ¡ as funÃ§Ãµes do RagAgent (ex: rag_agent_instance.rag_query()).
O TechLeadAgent usarÃ¡ a instÃ¢ncia do RagAgent como uma de suas ferramentas.
ConfiguraÃ§Ã£o do root_agent: No seu ponto de entrada principal (provavelmente agent.py na raiz do adk-rag-agent ou um novo main.py), configure o TechLeadAgent como o root_agent que serÃ¡ exposto pela interface web adk web.
6.2. Desenvolvimento dos Agentes Especializados (Engenheiro de Dados, Cientista de Dados, Dev Full-stack)
Para cada papel, defina um novo Agent no ADK (em suas respectivas pastas, como agents/data_engineer_agent/agent.py).
Escolha um LLM adequado (Gemini 1.5 Pro/Flash, Claude 3 Sonnet) para a tarefa.
Defina as ferramentas especÃ­ficas para suas habilidades (ex: query_bigquery, run_analysis, generate_api_spec).
O Agente Tech Lead serÃ¡ o responsÃ¡vel por chamar esses agentes especializados atravÃ©s de suas ferramentas, passando o contexto e os dados necessÃ¡rios.
6.3. OtimizaÃ§Ã£o e Refinamento
Monitoramento Ativo: Utilize Cloud Logging, Monitoring e Trace para acompanhar o desempenho, latÃªncia e custos de todas as interaÃ§Ãµes entre os agentes. Isso Ã© fundamental para identificar gargalos e otimizaÃ§Ãµes.
Teste de Ponta a Ponta: Crie cenÃ¡rios de teste abrangentes que envolvam a colaboraÃ§Ã£o de mÃºltiplos agentes para uma tarefa complexa.
GestÃ£o de Erros: Implemente um tratamento de erros robusto em todas as ferramentas e na lÃ³gica de orquestraÃ§Ã£o do Tech Lead.
SeguranÃ§a (ProduÃ§Ã£o): Migre o GITHUB_PERSONAL_ACCESS_TOKEN para o Secret Manager do GCP e configure a injeÃ§Ã£o via variÃ¡veis de ambiente para serviÃ§os como Cloud Run.
Escalabilidade (ProduÃ§Ã£o): Ao mover do Vertex AI Workbench, migre o Agente Tech Lead (e talvez os outros agentes) para serviÃ§os como Cloud Run para se beneficiar da escalabilidade automÃ¡tica e do modelo de custo pay-per-use.
