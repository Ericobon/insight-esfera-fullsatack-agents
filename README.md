# Vertex AI RAG Agent with ADK

üß† InsightEsfera - Equipe de Agentes de IA
Reposit√≥rio: https://github.com/Ericobon/insight-esfera-fullsatack-agents

1. Vis√£o Geral do Projeto
Este reposit√≥rio materializa a vis√£o da InsightEsfera de transformar desafios de neg√≥cios em oportunidades de crescimento atrav√©s de solu√ß√µes data-driven e automa√ß√£o inteligente. Desenvolvemos e implementamos um time colaborativo de agentes de Intelig√™ncia Artificial no Google Cloud Platform (GCP), focado em otimizar a entrega de valor aos nossos clientes.

Nosso time de agentes √© projetado para atuar como uma equipe de consultoria de dados e IA altamente eficiente, onde cada agente possui um papel bem definido, comunica-se de forma inteligente e contribui para a resolu√ß√£o de tarefas complexas, sob a orquestra√ß√£o de um Agente L√≠der T√©cnico.

Objetivos Chave:

Automa√ß√£o Inteligente: Automatizar e otimizar a coleta, engenharia, an√°lise, modelagem e integra√ß√£o de dados.
Decis√µes Data-Driven: Fornecer insights acion√°veis e baseados em evid√™ncias.
Escalabilidade e Custo-Benef√≠cio: Utilizar a infraestrutura serverless do GCP para garantir flexibilidade e otimiza√ß√£o de recursos (incluindo o consumo de tokens de LLM).
Colabora√ß√£o Eficaz: Estabelecer protocolos de comunica√ß√£o e compartilhamento de conhecimento entre agentes.
2. Componentes e Servi√ßos do Google Cloud Platform (GCP)
2.1. Ambiente de Desenvolvimento e Orquestra√ß√£o
Servi√ßo: Vertex AI Workbench (Managed Notebooks)
Nome da Inst√¢ncia: ie-agents
Propriet√°rio (Conta de Servi√ßo Principal): 487071349303-compute@developer.gserviceaccount.com
Regi√£o: us-central1 (Iowa) - Garante proximidade e lat√™ncia otimizada para os servi√ßos do Vertex AI.
Tipo de M√°quina: e2-standard-4 (4 vCPUs, 16 GB RAM) - Balanceado para desenvolvimento e orquestra√ß√£o sem GPU (o LLM √© externo).
Uso: Ambiente principal para desenvolvimento, depura√ß√£o e execu√ß√£o inicial do Agente Tech Lead e das fun√ß√µes-ferramentas.
2.2. Modelos de Linguagem (LLMs)
Utilizamos modelos de ponta do Vertex AI para o racioc√≠nio e gera√ß√£o de conte√∫do dos nossos agentes.

Para Racioc√≠nio Complexo e Orquestra√ß√£o (Agente Tech Lead):
Modelo: Claude 3 Opus (da Anthropic via Vertex AI Model Garden) - Excelente para compreens√£o complexa, racioc√≠nio de m√∫ltiplos passos e planejamento.
Uso: Ser√° o "c√©rebro" principal do Agente Tech Lead para decompor tarefas, delegar e sintetizar.
Para Gera√ß√£o Aumentada por Recupera√ß√£o (Agente RAG):
Modelo: Gemini 2.5 Flash Preview 04-17 (do Google via Vertex AI) - Otimizado para alta performance e menor lat√™ncia em opera√ß√µes RAG.
Uso: Pelo RagAgent para buscas e respostas baseadas em corpora de documentos.
Para Gera√ß√£o de Embeddings (Interno ao RAG Engine):
Modelo: publishers/google/models/text-embedding-005 (ou similar, gerenciado pelo Vertex AI RAG Engine).
Uso: Automaticamente pelo Vertex AI RAG Engine para criar as representa√ß√µes vetoriais dos documentos e consultas para a busca de similaridade.
2.3. Armazenamento de Dados e Mem√≥ria Persistente
Servi√ßo: Cloud Storage
Nome do Bucket: insightesfera-companies
Estrutura de Pastas:
insightesfera-companies/
‚îú‚îÄ‚îÄ companies/
‚îÇ   ‚îú‚îÄ‚îÄ [NOME_CLIENTE_1]/  # Ex: "InsightEsfera" (para projetos internos), "ClienteXYZ"
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ projects/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [NOME_PROJETO_CLIENTE_1_A]/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data/             # Dados brutos/processados espec√≠ficos do projeto
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reports/          # Relat√≥rios gerados pelo agente
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ memory/             # Mem√≥ria de longo prazo espec√≠fica do cliente
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ client_context.json   # Dados de prefer√™ncia, hist√≥rico, contatos
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ project_summary_latest.json # Resumo dos projetos do cliente
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ memory/                 # Mem√≥ria de longo prazo dos pr√≥prios agentes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tech_lead_knowledge.json  # Conhecimento do Tech Lead sobre fluxos e padr√µes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_engineer_skills.json # Conhecimento do Eng. Dados sobre fontes e formatos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ scripts/                # Templates de scripts ou snippets de c√≥digo para agentes
‚îÇ       ‚îú‚îÄ‚îÄ data_collection_templates.py
‚îÇ       ‚îî‚îÄ‚îÄ ml_model_templates.py
‚îú‚îÄ‚îÄ internal/                   # Dados internos da consultoria (templates de proposta, documenta√ß√£o interna)
‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ temp_github_ingest/         # **NOVO:** Pasta tempor√°ria para conte√∫do clonado do GitHub antes da ingest√£o RAG.
Uso: Reposit√≥rio centralizado para dados brutos, resultados, mem√≥ria de longo prazo (LTM) de clientes/agentes e arquivos tempor√°rios.
2.4. Bases de Conhecimento RAG
Servi√ßo: Vertex AI RAG Engine (anteriormente parte do Vertex AI Search)
Uso: Armazena os corpora (cole√ß√µes de documentos) que s√£o a base de conhecimento para a funcionalidade RAG. Os documentos s√£o processados (chunking, embedding, indexa√ß√£o) automaticamente por este servi√ßo.
Localiza√ß√£o no Console: Vertex AI > RAG Engine.
2.5. Comunica√ß√£o Externa e Serverless (Futura Escalabilidade)
Servi√ßo (Futuro): Cloud Run ou Cloud Functions
Uso: Para hospedar o Agente Tech Lead em produ√ß√£o, permitindo que ele seja acionado por requisi√ß√µes HTTP (ex: de plataformas como Twilio para integra√ß√£o WhatsApp) e escale para zero inst√¢ncias quando inativo, otimizando custos.
Servi√ßo (Integra√ß√£o WhatsApp - Futuro): Twilio ou Dialogflow CX
Uso: Gateway para comunica√ß√£o via WhatsApp com o Agente Tech Lead.
3. Arquitetura e Fluxo de Trabalho do Time de Agentes
Nosso time de agentes segue uma arquitetura colaborativa e hier√°rquica, orquestrada pelo Agente Tech Lead.

3.1. Agente Tech Lead (Orquestrador Principal)
Papel: O Agente L√≠der T√©cnico √© o maestro da equipe. Ele recebe as requisi√ß√µes, planeja a execu√ß√£o, delega tarefas aos agentes especializados e sintetiza os resultados. Possui uma vis√£o hol√≠stica e orientada a neg√≥cios.
LLM: Claude 3 Opus (via Vertex AI).
Fluxo de Intera√ß√£o:
Recebe uma requisi√ß√£o (ex: "Analise os dados de vendas do cliente X e identifique as principais tend√™ncias do √∫ltimo trimestre, incorporando tamb√©m a documenta√ß√£o do novo produto Y que est√° no nosso GitHub privado").
Planejamento: Decomp√µe a requisi√ß√£o em subtarefas (ex: "Verificar/Criar corpus do Cliente X", "Adicionar documenta√ß√£o do produto Y ao corpus", "Coletar dados de vendas", "Analisar dados", "Sintetizar relat√≥rio").
Delega√ß√£o: Chama as ferramentas dos agentes especializados apropriados para cada subtarefa.
Coordena√ß√£o: Monitora o status das subtarefas, lida com erros e combina os resultados parciais.
S√≠ntese: Utiliza o Claude Opus para gerar o relat√≥rio final ou a resposta completa, adicionando contexto e insights estrat√©gicos.
Persist√™ncia: Salva o hist√≥rico da intera√ß√£o e os resultados importantes na mem√≥ria de longo prazo (Cloud Storage).
3.2. Agentes Especializados (Sub-Agentes)
Cada agente especializado √© uma fun√ß√£o-ferramenta ou um m√≥dulo de c√≥digo Python invocado pelo Agente Tech Lead, utilizando um LLM e ferramentas espec√≠ficas para sua √°rea.

Vertex AI RAG Agent (rag_agent - Este reposit√≥rio):
Papel: Especialista em gerenciamento e consulta de bases de conhecimento documentais no Vertex AI RAG Engine.
LLM: Gemini 2.5 Flash (via Vertex AI) - Otimizado para RAG.
Ferramentas Expostas: rag_query, list_corpora, create_corpus, add_data (com suporte a GitHub), get_corpus_info, delete_corpus, delete_document.
Comunica√ß√£o: Recebe instru√ß√µes do Agente Tech Lead (via chamadas Python para suas fun√ß√µes-ferramentas) e retorna resultados estruturados.
Agente Engenheiro de Dados:
Papel: Respons√°vel pela coleta, limpeza, transforma√ß√£o e valida√ß√£o de dados de diversas fontes (BigQuery, Cloud Storage, APIs externas, bancos de dados).
LLM: Gemini 1.5 Pro ou Claude 3 Sonnet (via Vertex AI) - Bom para l√≥gica de transforma√ß√£o e valida√ß√£o de dados.
Ferramentas Expostas: fetch_from_bigquery(query), transform_data(data, schema), validate_data(data, rules), load_to_gcs(data, path).
Comunica√ß√£o: Recebe requisi√ß√µes de coleta/transforma√ß√£o do Tech Lead e entrega dados limpos/transformados (salvos em GCS) ou confirma√ß√µes.
Agente Cientista de Dados:
Papel: Focado em an√°lise de dados, identifica√ß√£o de padr√µes, constru√ß√£o/avalia√ß√£o de modelos preditivos e gera√ß√£o de insights acion√°veis.
LLM: Claude 3 Opus ou Gemini 1.5 Pro (via Vertex AI) - Para racioc√≠nio anal√≠tico avan√ßado.
Ferramentas Expostas: analyze_trends(data), run_ml_model(model_id, features), generate_insights(analysis_results), create_dashboard_spec(insights).
Comunica√ß√£o: Recebe dados do Tech Lead (geralmente via GCS), realiza an√°lises e retorna insights ou especifica√ß√µes de modelos.
Agente Desenvolvedor Full-stack:
Papel: Gera, refatora e integra c√≥digo para APIs, scripts de automa√ß√£o e interfaces simples, garantindo a interoperabilidade dos componentes.
LLM: Gemini 1.5 Pro (via Vertex AI) - Para gera√ß√£o de c√≥digo e entendimento de estruturas de software.
Ferramentas Expostas: generate_api_code(spec), create_automation_script(task_description), integrate_api(api1_spec, api2_spec).
Comunica√ß√£o: Recebe especifica√ß√µes do Tech Lead e retorna snippets de c√≥digo ou confirma√ß√µes de integra√ß√£o.
3.3. Papel Colaborativo Detalhado
A colabora√ß√£o ocorre atrav√©s de um loop cont√≠nuo de delega√ß√£o e feedback, mediado pelo Agente Tech Lead:

Delega√ß√£o Inteligente: O Tech Lead, usando seu LLM (Claude Opus), analisa a requisi√ß√£o e "decide" qual agente especializado e qual de suas ferramentas s√£o mais adequados para a pr√≥xima subtarefa.
Chamada de Ferramenta (Tool Calling): O Tech Lead invoca a fun√ß√£o Python que representa a ferramenta do agente especializado (ex: rag_agent_instance.add_data()).
Execu√ß√£o da Subtarefa: O agente especializado (o c√≥digo Python por tr√°s da ferramenta) executa sua l√≥gica, que pode envolver chamadas a servi√ßos do GCP (Vertex AI Search, BigQuery, Cloud Storage) ou a outros LLMs espec√≠ficos (como o Gemini Flash para RAG).
Compartilhamento de Resultados: Os resultados das subtarefas s√£o retornados ao Tech Lead (via retorno da fun√ß√£o Python). Para grandes volumes de dados, os resultados s√£o salvos em Cloud Storage, e apenas a refer√™ncia (URL do GCS) √© passada.
Ciclo de Feedback: O Tech Lead avalia o resultado. Se for insuficiente, amb√≠guo ou necessitar de corre√ß√£o, ele pode solicitar refinamentos ou chamar outro agente para uma etapa diferente.
Mem√≥ria Compartilhada: A mem√≥ria de longo prazo no Cloud Storage (insightesfera-companies/) serve como um "c√©rebro" compartilhado, onde os agentes podem persistir e recuperar informa√ß√µes relevantes para o projeto atual ou hist√≥rico de clientes.
4. Detalhes de Implementa√ß√£o e Ferramentas
4.1. Permiss√µes de IAM (Identity and Access Management)
A Conta de Servi√ßo principal da sua inst√¢ncia do Vertex AI Workbench (487071349303-compute@developer.gserviceaccount.com no projeto silent-text-458716-c9) necessita das seguintes permiss√µes para operar todos os agentes e suas ferramentas:

roles/aiplatform.user: Essencial para interagir com a API Vertex AI (incluindo LLMs como Claude Opus, Gemini, e o Vertex AI Search/RAG Engine).
roles/storage.admin: Para gerenciar (ler, gravar, deletar) todos os objetos no bucket insightesfera-companies. (Para maior granularidade em produ√ß√£o, considere roles/storage.objectAdmin e roles/storage.objectViewer para pastas espec√≠ficas).
roles/bigquery.dataEditor: Se os agentes precisarem escrever dados no BigQuery.
roles/bigquery.dataViewer: Se os agentes precisarem ler dados do BigQuery.
roles/bigquery.jobUser: Para executar jobs de BigQuery.
roles/iam.serviceAccountUser: Necess√°rio se o Agente Tech Lead for operar como outras contas de servi√ßo mais granulares para sub-agentes (n√£o estritamente necess√°rio para MVP).
roles/logging.logWriter: Para garantir que os logs da aplica√ß√£o sejam enviados para o Cloud Logging.
roles/sourcerepo.reader: Para ler reposit√≥rios no Cloud Source Repositories (se voc√™ optar por espelhar o GitHub para l√°).
4.2. Fun√ß√µes-Ferramentas (Python)
As "m√£os" e "olhos" dos agentes. Implementadas em Python, s√£o invocadas pelo LLM do agente supervisor (ou o pr√≥prio agente, se for aut√¥nomo).

rag_agent/tools/add_data.py: Implementado! Inclui l√≥gica para clonar reposit√≥rios GitHub para GCS e ingerir via Vertex AI RAG Engine.
rag_agent/tools/rag_query.py: Interage com o Vertex AI RAG Engine para consultas.
rag_agent/tools/create_corpus.py, list_corpora.py, get_corpus_info.py, delete_corpus.py, delete_document.py: Gerenciam os corpora no Vertex AI RAG Engine.
Novas Ferramentas para outros Agentes (futuro):
Engenheiro de Dados: fetch_from_bigquery, clean_and_transform_data, upload_to_gcs.
Cientista de Dados: run_descriptive_analysis, execute_prediction_model, generate_data_insights.
Dev Full-stack: generate_api_spec, create_boilerplate_code, perform_api_call.
4.3. Estrat√©gias de Mem√≥ria e RAG (Boas Pr√°ticas e Otimiza√ß√£o de Custos)
A implementa√ß√£o de mem√≥ria eficiente e RAG √© crucial para a intelig√™ncia e custo-benef√≠cio dos agentes.

Mem√≥ria de Curto Prazo (STM) - Gerenciamento de Janela de Contexto:
T√©cnica: Mant√©m as √∫ltimas N intera√ß√µes (mensagens/respostas) na mem√≥ria RAM do Agente Tech Lead.
Otimiza√ß√£o de Custos: Usamos LLMs com grandes janelas de contexto (Claude Opus), mas √© vital monitorar o tamanho do prompt. Para conversas muito longas, implemente:
Resumiza√ß√£o: O pr√≥prio LLM pode ser instru√≠do a periodicamente resumir partes mais antigas da conversa, compactando o contexto e reduzindo o consumo de tokens.
Sliding Window: Manter apenas as X mensagens mais recentes.
Mem√≥ria de Longo Prazo (LTM) - RAG com Vertex AI RAG Engine:
T√©cnica: Documentos de conhecimento (clientes, projetos, internos) s√£o armazenados no Cloud Storage e indexados no Vertex AI RAG Engine.
Processo:
Ingest√£o Otimizada: Documentos (incluindo de GitHub) s√£o divididos em chunks (pedacinhos de texto) e convertidos em embeddings pelo Vertex AI RAG Engine.
Busca de Relev√¢ncia (RAG): Quando uma pergunta surge, ela √© convertida em um embedding, e o Vertex AI RAG Engine encontra os chunks mais semanticamente relevantes na LTM.
Aumento do Prompt: Apenas os chunks mais relevantes s√£o adicionados ao prompt enviado ao LLM.
Otimiza√ß√£o de Custos de Tokens: O RAG √© a t√©cnica principal para reduzir o volume de tokens enviado ao LLM, pois evita que o LLM precise "ler" toda a base de conhecimento a cada requisi√ß√£o. Voc√™ paga apenas pelos tokens do prompt mais os tokens dos chunks relevantes recuperados.
Escolha do Embedding Model: O Vertex AI RAG Engine gerencia o modelo de embedding (text-embedding-005 ou similar), que √© otimizado para custo e precis√£o.
4.4. Monitoramento, Rastreabilidade e Controle de Custos
Para cada componente e cada intera√ß√£o:

Cloud Logging: Logs detalhados de todas as a√ß√µes dos agentes (in√≠cio/fim de tarefa, chamadas de ferramentas, erros, intera√ß√µes com LLMs) para depura√ß√£o e rastreabilidade do fluxo de trabalho.
Cloud Monitoring:
M√©tricas de Plataforma: CPU, RAM (Workbench/Cloud Run), requisi√ß√µes, lat√™ncia (Cloud Run, Vertex AI Search).
M√©tricas Customizadas: N√∫mero de tarefas conclu√≠das/falhas por agente, lat√™ncia m√©dia por tipo de tarefa, contagem de tokens (entrada/sa√≠da) por chamada de LLM (crucial para custo), volume de dados adicionados ao RAG Engine.
Alertas: Notifica√ß√µes proativas sobre erros, alto consumo de recursos ou estouro de or√ßamentos.
Cloud Trace: Visualiza√ß√£o do caminho completo de uma requisi√ß√£o (trace) atrav√©s de m√∫ltiplos agentes e servi√ßos, essencial para identificar gargalos de lat√™ncia. Instrumentar o c√≥digo com OpenTelemetry SDK.
Cloud Billing: Monitoramento regular dos relat√≥rios de custo, filtrando por Vertex AI (LLMs, RAG Engine), Cloud Storage e Compute Engine (Workbench). Configurar or√ßamentos com alertas para controlar gastos.
5. Estrutura de C√≥digo e Versionamento (GitHub)
Todo o c√≥digo-fonte, prompts e scripts auxiliares s√£o versionados no GitHub, garantindo colabora√ß√£o e rastreabilidade.

Reposit√≥rio: https://github.com/Ericobon/insight-esfera-fullsatack-agents

Estrutura de Pastas:

insight-esfera-fullsatack-agents/
‚îú‚îÄ‚îÄ docs/                             # Documenta√ß√£o do projeto (arquitetura, guias de setup)
‚îú‚îÄ‚îÄ agents/                           # C√≥digo dos agentes
‚îÇ   ‚îú‚îÄ‚îÄ rag_agent/                    # Implementa√ß√£o do Vertex AI RAG Agent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent.py                  # Defini√ß√£o do RagAgent (com o Instruction/Prompt)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts/                  # Arquivos de prompts/persona espec√≠ficos do RagAgent
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag_agent_persona.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools/                    # Implementa√ß√£o das ferramentas do RagAgent
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ add_data.py           # **ATUALIZADO (com l√≥gica GitHub)**
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ create_corpus.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ delete_corpus.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ delete_document.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ get_corpus_info.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ list_corpora.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag_query.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py                 # Configura√ß√µes do RagAgent (chunk size, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ tech_lead_agent/              # **NOVO:** Implementa√ß√£o do Agente Tech Lead
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent.py                  # Defini√ß√£o do TechLeadAgent (com o Instruction/Prompt)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts/                  # Arquivos de prompts/persona espec√≠ficos do TechLeadAgent
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tech_lead_persona.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tools/                    # Ferramentas que o TechLeadAgent usa (incluindo chamar o RagAgent)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ query_knowledge_base.py # Exemplo: Ferramenta que chama o RagAgent
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ... (outras ferramentas para BigQuery, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ data_engineer_agent/          # **PR√ìXIMO PASSO:** Futuro Agente Engenheiro de Dados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ data_scientist_agent/         # **PR√ìXIMO PASSO:** Futuro Agente Cientista de Dados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ dev_fullstack_agent/          # **PR√ìXIMO PASSO:** Futuro Agente Dev Full-stack
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ notebooks/                        # Notebooks Jupyter para desenvolvimento e experimenta√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ 01_adk_rag_agent_test.ipynb
‚îú‚îÄ‚îÄ config/                           # Arquivos de configura√ß√£o globais (se houver)
‚îú‚îÄ‚îÄ scripts/                          # Scripts de deploy, utilit√°rios
‚îú‚îÄ‚îÄ .env                              # **CR√çTICO:** Vari√°veis de ambiente LOCALMENTE (ADICIONADO AO .gitignore)
‚îú‚îÄ‚îÄ .gitignore                        # Para ignorar arquivos sens√≠veis e tempor√°rios
‚îú‚îÄ‚îÄ README.md                         # Este arquivo
‚îî‚îÄ‚îÄ requirements.txt                  # Depend√™ncias Python (atualizado com `GitPython`)
Versionamento por Agentes de IA:
A contribui√ß√£o dos agentes de IA ao versionamento ser√° de natureza colaborativa:

Gera√ß√£o de Artefatos: Agentes (como o Dev Full-stack) podem gerar trechos de c√≥digo ou especifica√ß√µes que, ap√≥s revis√£o humana, podem ser comitados.
Otimiza√ß√£o de Prompts: Insights de agentes sobre a efic√°cia dos prompts podem levar a melhorias nos arquivos agents/prompts/, que s√£o ent√£o versionados.
Relat√≥rios e An√°lises: Relat√≥rios ou sumariza√ß√µes gerados pelos agentes podem ser salvos no Cloud Storage e seus metadados versionados, com links nos relat√≥rios gerados.
6. Pr√≥ximos Passos Cruciais para a Integra√ß√£o Completa
Agora que o RagAgent est√° funcionando e integrado ao GitHub, o foco √© construir o restante do time.

6.1. Configura√ß√£o do TechLeadAgent e Orquestra√ß√£o
Defini√ß√£o do TechLeadAgent: Crie o arquivo agents/tech_lead_agent/agent.py definindo o Agent (com o Claude 3 Opus) e seu instruction (prompt).
Cria√ß√£o das Ferramentas do Tech Lead:
Crie agents/tech_lead_agent/tools/query_knowledge_base.py (e outras ferramentas, se necess√°rio). Esta ferramenta chamar√° as fun√ß√µes do RagAgent (ex: rag_agent_instance.rag_query()).
O TechLeadAgent usar√° a inst√¢ncia do RagAgent como uma de suas ferramentas.
Configura√ß√£o do root_agent: No seu ponto de entrada principal (provavelmente agent.py na raiz do adk-rag-agent ou um novo main.py), configure o TechLeadAgent como o root_agent que ser√° exposto pela interface web adk web.
6.2. Desenvolvimento dos Agentes Especializados (Engenheiro de Dados, Cientista de Dados, Dev Full-stack)
Para cada papel, defina um novo Agent no ADK (em suas respectivas pastas, como agents/data_engineer_agent/agent.py).
Escolha um LLM adequado (Gemini 1.5 Pro/Flash, Claude 3 Sonnet) para a tarefa.
Defina as ferramentas espec√≠ficas para suas habilidades (ex: query_bigquery, run_analysis, generate_api_spec).
O Agente Tech Lead ser√° o respons√°vel por chamar esses agentes especializados atrav√©s de suas ferramentas, passando o contexto e os dados necess√°rios.
6.3. Otimiza√ß√£o e Refinamento
Monitoramento Ativo: Utilize Cloud Logging, Monitoring e Trace para acompanhar o desempenho, lat√™ncia e custos de todas as intera√ß√µes entre os agentes. Isso √© fundamental para identificar gargalos e otimiza√ß√µes.
Teste de Ponta a Ponta: Crie cen√°rios de teste abrangentes que envolvam a colabora√ß√£o de m√∫ltiplos agentes para uma tarefa complexa.
Gest√£o de Erros: Implemente um tratamento de erros robusto em todas as ferramentas e na l√≥gica de orquestra√ß√£o do Tech Lead.
Seguran√ßa (Produ√ß√£o): Migre o GITHUB_PERSONAL_ACCESS_TOKEN para o Secret Manager do GCP e configure a inje√ß√£o via vari√°veis de ambiente para servi√ßos como Cloud Run.
Escalabilidade (Produ√ß√£o): Ao mover do Vertex AI Workbench, migre o Agente Tech Lead (e talvez os outros agentes) para servi√ßos como Cloud Run para se beneficiar da escalabilidade autom√°tica e do modelo de custo pay-per-use.
